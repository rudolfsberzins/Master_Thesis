{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import sys\n",
    "from sys import argv\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import glob\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def open_entities(ents_name):\n",
    "\n",
    "\tents = pd.read_csv(ents_name, sep = '\\t', names = ['Given_ID', 'UNUSED', 'Real_ID'])\n",
    "\n",
    "\treturn ents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def open_nec_pairs(pairs_name):\n",
    "    \n",
    "    nec_pairs = pd.read_csv(pairs_name, sep = '\\t', names = [\"Entity_name_x\",\"SerialNo_x\", \"Entity_name_y\", \"SerialNo_y\", \"Text\"])\n",
    "    \n",
    "    return nec_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "entities = open_entities(\"./yeast/yeast_entities.tsv\")\n",
    "pairs_nec = open_nec_pairs(\"./Results/Pairs_With_Sentences_Only_nec.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pairs_nec[[\"SerialNo_x\", \"SerialNo_y\"]] = pairs_nec[[\"SerialNo_x\", \"SerialNo_y\"]].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't mask  SOS1 \n",
      "Trying a different way\n",
      "Knockdown of PIP4K2A, CCT5, CMBL, , KMO and OPN3, genes within 200 kb up-/downstream of the 3 SNPs that were associated with SCLC overall survival (rs1778335, rs2662411 and rs7519667), significantly desensitized H196 to paclitaxel.\n",
      "Couldn't mask  inorganic pyrophosphatase \n",
      "Trying a different way\n",
      "BP variability also significantly decreased: of diurnal SBP/.8/4.1 mm Hg (21.7/24.7%), of nocturnal SBP/DBP - 2.8/4.1 mm Hg (17.9/19.6%).\n",
      "Couldn't mask  superoxide dismutase [Cu-Zn \n",
      "Trying a different way\n",
      "Among them, 9 proteins (translation elongation factor eEF-1 alpha chain,  III, annexin II, calcyclin, fab fragment anti-VEGF antibody, peroxiredoxin-2, ], stefin A3, and calgranulin-B) were common and showed similar expression pattern in glyphosate and TPA-treated mouse skin.\n",
      "Couldn't mask  ORM1 \n",
      "Trying a different way\n",
      "Embryos cultured in 1.69mM arginine had lower SLC7A1 levels and a higher abundance of messages involved with glycolysis (hexokinase 1, hexokinase 2 and glutamic pyruvate transaminase (alanine aminotransferase) 2) and decreased expression of genes involved with blocking the tricarboxylic acid cycle (pyruvate dehydrogenase kinase, isozyme 1) and the pentose phosphate pathway ( 1).\n",
      "Couldn't mask  Na(+)/H(+) antiporter \n",
      "Trying a different way\n",
      "This phosphorylation anchors the SCaBP8-SOS2 complex on plasma membrane and activates PM , such as .\n",
      "Couldn't mask  glutamate synthase (NADH \n",
      "Trying a different way\n",
      "In addition, we found that several genes, such as phosphatidylinositol 3-kinase  and ), had good resolution in this group (even when used alone).\n",
      "Couldn't mask  superoxide dismutase [Cu-Zn \n",
      "Trying a different way\n",
      "Among the 20 identified proteins with altered expression, small heat shock protein 27 (HSP27) and ] were down-regulated while -1 was up-regulated significantly in response to the chemical challenge.\n",
      "Couldn't mask  Na(+)/H(+) antiporter \n",
      "Trying a different way\n",
      "Thus, a very rapid efflux of Na(+) from roots must occur to control net rates of influx.\n",
      "Couldn't mask  carbonic anhydrase \n",
      "Trying a different way\n",
      "Moreover, erythrocytes antioxidant enzymes such as superoxide dismutase, catalase, glutathione peroxide, glutathione reductase, glutathione-S-transferase, and  activities and non-enzymatic antioxidants such as vitamin C, vitamin E, reduced glutathione (GSH), and oxidized glutathione (GSSG) levels were altered.\n",
      "Couldn't mask  Rad27 \n",
      "Trying a different way\n",
      "To study repair of DNA double-strand breaks (DSBs) in mammalian chromosomes, we designed DNA substrates containing a thymidine kinase (TK) gene disrupted by the 18-bp recognition site for yeast endonuclease I-.\n",
      "Couldn't mask  Na(+)/H(+) antiporter \n",
      "Trying a different way\n",
      "The insert of pAM2 (1,886 bp) derived from  contained a gene (1,185 bp) which encodes a novel  belonging to the NhaA family.\n",
      "Couldn't mask  malate dehydrogenase (oxaloacetate-decarboxylating \n",
      "Trying a different way\n",
      "In rats fed on the Cys-deficient diet there was an expected decrease in growth but an unexpected increase in the activities of  (EC 1.1.1.49) and ) (NADP+) (EC 1.1.1.40).\n",
      "Couldn't mask  ribonuclease H \n",
      "Trying a different way\n",
      "The yeast regulatory gene PHO2 encodes a protein assumed to activate, in concert with the PHO4 protein, the transcription of the repressible acid phosphatase-coding gene .\n",
      "Couldn't mask  alpha-2 \n",
      "Trying a different way\n",
      "We developed primers that amplify two short Y-specific fragments (SRY1 and AMELY2) and one longer X-specific fragment (), developed from elephant sequences in one multiplex PCR.\n",
      "Couldn't mask  RNase H(35 \n",
      "Trying a different way\n",
      "Screening of yeast deletion mutant cells reveals that the initial nick is made by ), a RNase H type 2 enzyme, and the second cut is made by , the yeast homologue of human FEN-1 protein.\n",
      "Couldn't mask  glutamine synthetase \n",
      "Trying a different way\n",
      "In this case, the regulation requires MEC1 and , as well as other checkpoint genes.\n",
      "Couldn't mask  Spc1 \n",
      "Trying a different way\n",
      "Rsc1p and Rsc2p, two other RSC subunits, physically interact with  and Mre11p.\n",
      "Couldn't mask  glutamate synthase (NADH \n",
      "Trying a different way\n",
      "Activities of several enzymes involved in nitrogen and carbon metabolism including nitrate reductase (NR),  (GS), -GOGAT), NADP-dependent isocitrate dehydrogenase (NADP-ICDH), and phosphoenol pyruvate carboxylase (PEPCase) were regulated by GABA in the growth medium.\n",
      "Couldn't mask  nucleotidase \n",
      "Trying a different way\n",
      "We show that destruction of Pds1p is the APC's sole role in triggering Scc1p's dissociation from chromatids and that Pds1p forms a stable complex with a 180 kDa protein called , which is essential for the dissociation of Scc1p from sister chromatids and for their separation.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-33502860cbd6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m#Add Real_ID's\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"SerialNo_x\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Given_ID\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"SerialNo_y\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Given_ID\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Given_ID\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"SerialNo_x\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Real_ID\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mentities\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mentities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Given_ID\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"SerialNo_y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"Real_ID\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pairs_copy = pairs_nec.copy()\n",
    "for i,r in pairs_copy.iterrows():\n",
    "    \n",
    "    #Add Real_ID's\n",
    "    if r[\"SerialNo_x\"] in set(entities[\"Given_ID\"].tolist()) and r[\"SerialNo_y\"] in set(entities[\"Given_ID\"].tolist()):\n",
    "        x = entities.loc[entities[\"Given_ID\"] == r[\"SerialNo_x\"], (\"Real_ID\")]\n",
    "        y = entities.loc[entities[\"Given_ID\"] == r[\"SerialNo_y\"], (\"Real_ID\")]\n",
    "        pairs_copy.set_value(i, \"Real_ID_x\", x.values[0])\n",
    "        pairs_copy.set_value(i, \"Real_ID_y\", y.values[0])\n",
    "        \n",
    "            \n",
    "    #Mask entity names in text\n",
    "    try:\n",
    "        sub1 = re.sub(r[\"Entity_name_x\"], '', r[\"Text\"])\n",
    "        sub2 = re.sub(r[\"Entity_name_y\"], '', sub1)\n",
    "    except re.error:\n",
    "        print \"Couldn't mask \", r[\"Entity_name_y\"], \"\\n\", \"Trying a different way\"\n",
    "        sub2 = sub1.replace(r[\"Entity_name_y\"], \"\")\n",
    "        print sub2\n",
    "    \n",
    "#     pairs_copy.set_value(i, \"Text\", sub2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'teing'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bow_df = pairs_copy[[\"Real_ID_x\", \"Real_ID_y\", \"Text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped = bow_df.groupby([\"Real_ID_x\", \"Real_ID_y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped_text = grouped['Text'].apply(lambda x: ','.join(x.astype(str))).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-e2b4d4fc7f37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpair\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Real_ID_x\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Real_ID_y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m#Check if there is a reverse version of the pair\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mgrouped_text\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'@pair[0] == Real_ID_y and @pair[1] == Real_ID_x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#necessary to not catch the original\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bioinformatics/.local/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mquery\u001b[0;34m(self, expr, inplace, **kwargs)\u001b[0m\n\u001b[1;32m   2208\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'level'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'level'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2209\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2210\u001b[0;31m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2212\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bioinformatics/.local/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36meval\u001b[0;34m(self, expr, inplace, **kwargs)\u001b[0m\n\u001b[1;32m   2277\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'target'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2278\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'resolvers'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'resolvers'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolvers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2279\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2281\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bioinformatics/.local/lib/python2.7/site-packages/pandas/computation/eval.pyc\u001b[0m in \u001b[0;36meval\u001b[0;34m(expr, parser, engine, truediv, local_dict, global_dict, resolvers, level, target, inplace)\u001b[0m\n\u001b[1;32m    264\u001b[0m         \u001b[0meng\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_engines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0meng_inst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meng\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparsed_expr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meng_inst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mparsed_expr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0massigner\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mmulti_line\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bioinformatics/.local/lib/python2.7/site-packages/pandas/computation/engines.pyc\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 145\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bioinformatics/.local/lib/python2.7/site-packages/pandas/computation/expr.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    731\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 732\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mterms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    733\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    734\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__unicode__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bioinformatics/.local/lib/python2.7/site-packages/pandas/computation/ops.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, env)\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0mright\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrhs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mright\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterm_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meval_in_python\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bioinformatics/.local/lib/python2.7/site-packages/pandas/core/ops.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    917\u001b[0m                       else fill_bool)\n\u001b[1;32m    918\u001b[0m             return filler(self._constructor(na_op(self.values, other.values),\n\u001b[0;32m--> 919\u001b[0;31m                                             index=self.index, name=name))\n\u001b[0m\u001b[1;32m    920\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bioinformatics/.local/lib/python2.7/site-packages/pandas/core/ops.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    905\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m         \u001b[0mfill_int\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 907\u001b[0;31m         \u001b[0mfill_bool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_align_method_SERIES\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malign_asobject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bioinformatics/.local/lib/python2.7/site-packages/pandas/core/series.pyc\u001b[0m in \u001b[0;36mfillna\u001b[0;34m(self, value, method, axis, inplace, limit, downcast, **kwargs)\u001b[0m\n\u001b[1;32m   2366\u001b[0m                                           \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2367\u001b[0m                                           \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdowncast\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdowncast\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2368\u001b[0;31m                                           **kwargs)\n\u001b[0m\u001b[1;32m   2369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2370\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mAppender\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shared_docs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'shift'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0m_shared_doc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bioinformatics/.local/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mfillna\u001b[0;34m(self, value, method, axis, inplace, limit, downcast)\u001b[0m\n\u001b[1;32m   3268\u001b[0m                 new_data = self._data.fillna(value=value, limit=limit,\n\u001b[1;32m   3269\u001b[0m                                              \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3270\u001b[0;31m                                              downcast=downcast)\n\u001b[0m\u001b[1;32m   3271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3272\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bioinformatics/.local/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mfillna\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m   3181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3182\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfillna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3183\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fillna'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3185\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdowncast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bioinformatics/.local/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[1;32m   3010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3011\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconsolidate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3012\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mf\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'where'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bioinformatics/.local/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36m_consolidate_inplace\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   4199\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4201\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m_consolidate_inplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4202\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "col_names = [\"Real_ID_x\", \"Real_ID_y\", \"Text\"]\n",
    "temp_df = pd.DataFrame(columns = col_names)\n",
    "exclude = []\n",
    "for i,r in grouped_text.iterrows():\n",
    "    pair = [r[\"Real_ID_x\"], r[\"Real_ID_y\"]]\n",
    "    #Check if there is a reverse version of the pair\n",
    "    if grouped_text.query('@pair[0] == Real_ID_y and @pair[1] == Real_ID_x').empty: \n",
    "        pass\n",
    "    elif r.name not in exclude: #necessary to not catch the original\n",
    "        temp = grouped_text.query('@pair[0] == Real_ID_y and @pair[1] == Real_ID_x')\n",
    "        exclude.append(temp.index[0])\n",
    "        temp_df = temp_df.append(temp, ignore_index = True)\n",
    "\n",
    "#Switch column names\n",
    "col_list = list(temp_df)\n",
    "col_list[0], col_list[1] = col_list[1], col_list[0]\n",
    "temp_df.columns = col_list\n",
    "temp_df = temp_df[[\"Real_ID_x\", \"Real_ID_y\", \"Text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_grouped_text = grouped_text.append(temp_df, ignore_index = True).groupby([\"Real_ID_x\", \"Real_ID_y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grouped_final = new_grouped_text['Text'].apply(lambda x: ','.join(x.astype(str))).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def open_interactions(interactions_name):\n",
    "\t\"\"\"Opens a TSV File Containing the Interactions from STRING DB\n",
    "\n",
    "\tINPUT: Name of the tsv file\n",
    "\n",
    "\tOUTPUT: Pandas DataFrame of the .tsv file\"\"\"\n",
    "\t\n",
    "\tinteractions_file = pd.read_csv(interactions_name, sep = '\\t')\n",
    "\n",
    "\treturn interactions_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def check_interaction(interactions, tries = 0):\n",
    "    desired_interaction = raw_input(\"What interaction will be positive?: \")\n",
    "    if desired_interaction in interactions[\"mode\"].tolist():\n",
    "        return desired_interaction\n",
    "    elif tries < 10:\n",
    "        print \"There isn't such interaction. Try again\"\n",
    "        tries+=1\n",
    "        check_interaction(interactions, tries)\n",
    "    elif tries == 10:\n",
    "        print \"You are hopeless. Please check interaction again! Defaulting to physical binding!\"\n",
    "        desired_interaction = \"binding\"\n",
    "        return desired_interaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What interaction will be positive?: binding\n"
     ]
    }
   ],
   "source": [
    "interactions = open_interactions(\"./4932.protein.actions.v10.txt/4932.protein.actions.v10.txt\")\n",
    "\n",
    "\n",
    "interactions[\"item_id_a\"] = interactions[\"item_id_a\"].str[5:]\n",
    "interactions[\"item_id_b\"] = interactions[\"item_id_b\"].str[5:]\n",
    "interactions = interactions[[\"item_id_a\", \"item_id_b\", \"mode\"]]\n",
    "desired_interaction = check_interaction(interactions, 0)\n",
    "\n",
    "for i,r in grouped_final.iterrows():\n",
    "    pre_mode = interactions.loc[interactions[\"item_id_a\"] == r[\"Real_ID_x\"]]\n",
    "    mode = pre_mode.loc[pre_mode[\"item_id_b\"] == r[\"Real_ID_y\"], (\"mode\")]\n",
    "    if mode.empty or desired_interaction not in mode.values:\n",
    "        grouped_final.set_value(i, \"Mode\", 0)\n",
    "    elif desired_interaction in mode.values:\n",
    "        grouped_final.set_value(i, \"Mode\", 1)\n",
    "        \n",
    "grouped_final[\"Mode\"] = grouped_final[\"Mode\"].astype(int)\n",
    "grouped_final = grouped_final[[\"Real_ID_x\", \"Real_ID_y\", \"Mode\", \"Text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def split_train_test(bow_df):\n",
    "\n",
    "\tdata = bow_df[[\"Real_ID_x\", \"Real_ID_y\", \"Text\"]]\n",
    "\tlabels = bow_df[\"Mode\"]\n",
    "\n",
    "\ttest_s = input(\"What is the size of test? (0-1, float): \")\n",
    "\tran_state = input(\"Set random state (int): \")\n",
    "\n",
    "\tdata_train, data_test, labels_train, labels_test = train_test_split(data, labels, test_size=test_s, random_state=ran_state)\n",
    "\n",
    "\treturn data_train.reset_index(drop=True), data_test.reset_index(drop=True), labels_train.reset_index(drop=True), labels_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the size of test? (0-1, float): 0.3\n",
      "Set random state (int): 1993\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test, labels_train, labels_test = split_train_test(grouped_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def texts_to_words( raw_text ):\n",
    "    # Function to convert a raw text to a string of words\n",
    "    # The input is a single string (a raw text), and \n",
    "    # the output is a single string (a preprocessed text)\n",
    "    #\n",
    "    # 2. Remove non-letters        \n",
    "    letters_only = re.sub(\"[^a-zA-Z0-9]\", \" \", raw_text) \n",
    "    #\n",
    "    # 3. Convert to lower case, split into individual words\n",
    "    words = letters_only.lower().split()                             \n",
    "    #\n",
    "    # 4. In Python, searching a set is much faster than searching\n",
    "    #   a list, so convert the stop words to a set\n",
    "    stops = set(stopwords.words(\"english\"))                  \n",
    "    # \n",
    "    # 5. Remove stop words\n",
    "    meaningful_words = [w for w in words if not w in stops]   \n",
    "    #\n",
    "    # 6. Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return( \" \".join( meaningful_words ))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the size of test? (0-1, float): 0.3\n",
      "Set random state (int): 1993\n",
      "Cleaning and parsing the training set article sentences...\n",
      "\n",
      "Texts 1000 of 22558\n",
      "\n",
      "Texts 2000 of 22558\n",
      "\n",
      "Texts 3000 of 22558\n",
      "\n",
      "Texts 4000 of 22558\n",
      "\n",
      "Texts 5000 of 22558\n",
      "\n",
      "Texts 6000 of 22558\n",
      "\n",
      "Texts 7000 of 22558\n",
      "\n",
      "Texts 8000 of 22558\n",
      "\n",
      "Texts 9000 of 22558\n",
      "\n",
      "Texts 10000 of 22558\n",
      "\n",
      "Texts 11000 of 22558\n",
      "\n",
      "Texts 12000 of 22558\n",
      "\n",
      "Texts 13000 of 22558\n",
      "\n",
      "Texts 14000 of 22558\n",
      "\n",
      "Texts 15000 of 22558\n",
      "\n",
      "Texts 16000 of 22558\n",
      "\n",
      "Texts 17000 of 22558\n",
      "\n",
      "Texts 18000 of 22558\n",
      "\n",
      "Texts 19000 of 22558\n",
      "\n",
      "Texts 20000 of 22558\n",
      "\n",
      "Texts 21000 of 22558\n",
      "\n",
      "Texts 22000 of 22558\n",
      "\n",
      "Creating the bag of words...\n",
      "\n",
      "Training the random forest...\n",
      "Cleaning and parsing the test set movie reviews...\n",
      "\n",
      "Review 1000 of 9669\n",
      "\n",
      "Review 2000 of 9669\n",
      "\n",
      "Review 3000 of 9669\n",
      "\n",
      "Review 4000 of 9669\n",
      "\n",
      "Review 5000 of 9669\n",
      "\n",
      "Review 6000 of 9669\n",
      "\n",
      "Review 7000 of 9669\n",
      "\n",
      "Review 8000 of 9669\n",
      "\n",
      "Review 9000 of 9669\n",
      "\n",
      "Predicting based on model...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test, labels_train, labels_test = split_train_test(result_bow_df)\n",
    "\n",
    "# Get the number of reviews based on the dataframe column size\n",
    "num_texts = data_train[\"Text\"].size\n",
    "# Initialize an empty list to hold the clean reviews\n",
    "print \"Cleaning and parsing the training set article sentences...\\n\"\n",
    "clean_train_texts = []\n",
    "for i in xrange( 0, num_texts ):\n",
    "    # If the index is evenly divisible by 1000, print a message\n",
    "    if( (i+1)%1000 == 0 ):\n",
    "        print \"Texts %d of %d\\n\" % ( i+1, num_texts )                                                                    \n",
    "    clean_train_texts.append( texts_to_words( data_train[\"Text\"][i] ))\n",
    "\n",
    "print \"Creating the bag of words...\\n\"\n",
    "# Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "# bag of words tool.  \n",
    "vectorizer = CountVectorizer(analyzer = \"word\",   \\\n",
    "                             tokenizer = None,    \\\n",
    "                             preprocessor = None, \\\n",
    "                             stop_words = None,   \\\n",
    "                             max_features = 5000) \n",
    "\n",
    "# fit_transform() does two functions: First, it fits the model\n",
    "# and learns the vocabulary; second, it transforms our training data\n",
    "# into feature vectors. The input to fit_transform should be a list of \n",
    "# strings.\n",
    "train_data_features = vectorizer.fit_transform(clean_train_texts)\n",
    "\n",
    "# Numpy arrays are easy to work with, so convert the result to an \n",
    "# array\n",
    "train_data_features = train_data_features.toarray()\n",
    "\n",
    "print \"Training the random forest...\"\n",
    "\n",
    "# Initialize a Random Forest classifier with 100 trees\n",
    "forest = RandomForestClassifier(n_estimators = 100) \n",
    "\n",
    "# Fit the forest to the training set, using the bag of words as \n",
    "# features and the sentiment labels as the response variable\n",
    "#\n",
    "# This may take a few minutes to run\n",
    "forest = forest.fit( train_data_features, labels_train)\n",
    "\n",
    "num_texts = len(data_test[\"Text\"])\n",
    "clean_test_texts = [] \n",
    "\n",
    "print \"Cleaning and parsing the test set movie reviews...\\n\"\n",
    "for i in xrange(0,num_texts):\n",
    "    if( (i+1) % 1000 == 0 ):\n",
    "        print \"Review %d of %d\\n\" % (i+1, num_texts)\n",
    "    clean_texts = texts_to_words( data_test[\"Text\"][i] )\n",
    "    clean_test_texts.append( clean_texts )\n",
    "\n",
    "# Get a bag of words for the test set, and convert to a numpy array\n",
    "test_data_features = vectorizer.transform(clean_test_texts)\n",
    "test_data_features = test_data_features.toarray()\n",
    "\n",
    "# Use the random forest to make sentiment label predictions\n",
    "print \"Predicting based on model...\"\n",
    "result = forest.predict(test_data_features)\n",
    "print \"Done!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_accuracy(l_new, l_te):\n",
    "    \"\"\"Calculates the accuracy of predicted labels, based on the given labels\n",
    "\n",
    "    INPUT: New(Predicted) Labels, Test Labels\n",
    "\n",
    "    OUTPUT: Accuracy in percent \"\"\"\n",
    "\n",
    "    acc = 0\n",
    "    for i in range(len(l_te)):\n",
    "        if l_new[i] == l_te[i]:\n",
    "            acc += 1\n",
    "    acc = acc/len(l_te)\n",
    "\n",
    "    return 1-acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error = get_accuracy(pred_labels, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15875478332816217"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def open_bow_df(bow_name):\n",
    "    \n",
    "    bow_df_file = pd.read_csv(bow_name, sep = \"\\t\")\n",
    "    \n",
    "    return bow_df_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_bow_df = open_bow_df(\"./Results/Bag_of_Words_df.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-200fa75d4b5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_data_features' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(solver='adam', alpha=1e-5, random_state=1)\n",
    "\n",
    "model = clf.fit(train_data_features, labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_labels = clf.predict(test_data_features)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
