{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import pandas as pd\n",
    "import sys\n",
    "from sys import argv\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def open_bow_df(bow_name):\n",
    "    \n",
    "    bow_df_file = pd.read_csv(bow_name, sep = \"\\t\")\n",
    "    \n",
    "    return bow_df_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def split_train_test(bow_df):\n",
    "\n",
    "    data = bow_df[[\"Real_ID_x\", \"Real_ID_y\", \"Text\"]]\n",
    "    labels = bow_df[\"Mode\"]\n",
    "\n",
    "    test_s = 0.3 #input(\"What is the size of test? (0-1, float): \")\n",
    "    ran_state = 1993 #input(\"Set random state (int): \")\n",
    "\n",
    "    data_train, data_test, labels_train, labels_test = train_test_split(data, labels, test_size=test_s, random_state=ran_state)\n",
    "    data_train, data_test, labels_train, labels_test = data_train.reset_index(drop=True), data_test.reset_index(drop=True), labels_train.reset_index(drop=True), labels_test.reset_index(drop=True) \n",
    "\n",
    "    return data_train, data_test, labels_train, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def texts_to_words( raw_text ):\n",
    "\t# Function to convert a raw text to a string of words\n",
    "\t# The input is a single string (a raw text), and \n",
    "\t# the output is a single string (a preprocessed text)\n",
    "\t#\n",
    "\t# 2. Remove non-letters        \n",
    "\tletters_only = re.sub(\"[^a-zA-Z0-9]\", \" \", raw_text) \n",
    "\t#\n",
    "\t# 3. Convert to lower case, split into individual words\n",
    "\twords = letters_only.lower().split()                             \n",
    "\t#\n",
    "\t# 4. In Python, searching a set is much faster than searching\n",
    "\t#   a list, so convert the stop words to a set\n",
    "\tstops = set(stopwords.words(\"english\"))                  \n",
    "\t# \n",
    "\t# 5. Remove stop words\n",
    "\tmeaningful_words = [w for w in words if not w in stops]   \n",
    "\t#\n",
    "\t# 6. Join the words back into one string separated by space, \n",
    "\t# and return the result.\n",
    "\treturn( \" \".join( meaningful_words ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def bag_of_words_and_prediction(bow_df, feature_count):\n",
    "\n",
    "    data_train, data_test, labels_train, labels_test = split_train_test(bow_df)\n",
    "\n",
    "    # Get the number of reviews based on the dataframe column size\n",
    "    num_texts = data_train[\"Text\"].size\n",
    "\n",
    "    # Initialize an empty list to hold the clean reviews\n",
    "    print \"Cleaning and parsing the training set article sentences...\\n\"\n",
    "    clean_train_texts = []\n",
    "    for i in xrange( 0, num_texts ):\n",
    "        # If the index is evenly divisible by 1000, print a message\n",
    "        # if( (i+1)%100 == 0 ):\n",
    "            # print \"Texts %d of %d\\n\" % ( i+1, num_texts )                                                                    \n",
    "        clean_train_texts.append( texts_to_words( data_train[\"Text\"][i] ))\n",
    "\n",
    "    print \"Creating the bag of words...\\n\"\n",
    "    # Initialize the \"CountVectorizer\" object, which is scikit-learn's\n",
    "    # bag of words tool.  \n",
    "    vectorizer = CountVectorizer(analyzer = \"word\", tokenizer = None, preprocessor = None, stop_words = None, max_features = feature_count) \n",
    "\n",
    "    # fit_transform() does two functions: First, it fits the model\n",
    "    # and learns the vocabulary; second, it transforms our training data\n",
    "    # into feature vectors. The input to fit_transform should be a list of \n",
    "    # strings.\n",
    "    train_data_features = vectorizer.fit_transform(clean_train_texts)\n",
    "\n",
    "    # Numpy arrays are easy to work with, so convert the result to an \n",
    "    # array\n",
    "    train_data_features = train_data_features.toarray()\n",
    "\n",
    "    num_texts = len(data_test[\"Text\"])\n",
    "    clean_test_texts = [] \n",
    "\n",
    "    print \"Cleaning and parsing the test set movie reviews...\\n\"\n",
    "    for i in xrange(0,num_texts):\n",
    "        # if( (i+1) % 1000 == 0 ):\n",
    "            # print \"Review %d of %d\\n\" % (i+1, num_texts)\n",
    "        clean_texts = texts_to_words( data_test[\"Text\"][i] )\n",
    "        clean_test_texts.append( clean_texts )\n",
    "\n",
    "    # Get a bag of words for the test set, and convert to a numpy array\n",
    "    test_data_features = vectorizer.transform(clean_test_texts)\n",
    "    test_data_features = test_data_features.toarray()\n",
    "\n",
    "    print \"Done! Produced train, test split with \", feature_count, \" features\"\n",
    "\n",
    "    return train_data_features, test_data_features, labels_train, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_accuracy(l_new, l_te):\n",
    "    \"\"\"Calculates the accuracy of predicted labels, based on the given labels\n",
    "\n",
    "    INPUT: New(Predicted) Labels, Test Labels\n",
    "\n",
    "    OUTPUT: Accuracy in percent \"\"\"\n",
    "\n",
    "    acc = 0\n",
    "    for i in range(len(l_te)):\n",
    "        if l_new[i] == l_te[i]:\n",
    "            acc += 1\n",
    "    acc = acc/len(l_te)\n",
    "\n",
    "    return 1-acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def linear_reg_model(train_features, test_features, labels_train, labels_test):\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print \"Training Linear Regression model... \"\n",
    "    linear = LinearRegression(normalize = True)\n",
    "    \n",
    "    model = linear.fit(train_features, labels_train)\n",
    "    \n",
    "    print \"Predicting based on model... \"\n",
    "    result = model.predict(test_features)\n",
    "    \n",
    "    print \"Calculating error...\"\n",
    "    error = get_accuracy(result, labels_test)\n",
    "    \n",
    "    print \"The error of linear regression (normalized) \", error\n",
    "    \n",
    "    print \"Done\"\n",
    "    \n",
    "    finish_time = time.time() - start_time\n",
    "    print \"This took %s seconds\" %(finish_time)\n",
    "    return result, error, finish_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logistic_reg_model(train_features, test_features, labels_train, labels_test):\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    start_time = time.time()\n",
    "    \n",
    "    print \"Training Logistic Regression model... \"\n",
    "    logistic = LogisticRegression()\n",
    "    \n",
    "    model = logistic.fit(train_features, labels_train)\n",
    "    \n",
    "    print \"Predicting based on model... \"\n",
    "    result = model.predict(test_features)\n",
    "    \n",
    "    print \"Calculating error...\"\n",
    "    error = get_accuracy(result, labels_test)\n",
    "    \n",
    "    print \"The error of logistic regression \", error\n",
    "    \n",
    "    print \"Done\"\n",
    "    \n",
    "    finish_time = time.time() - start_time\n",
    "    print \"This took %s seconds\" %(finish_time)    \n",
    "    return result, error, finish_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def SVM_model(train_features, test_features, labels_train, labels_test):\n",
    "    from sklearn import svm\n",
    "    start_time = time.time()\n",
    "    print \"Training Support Vector Machines model... \"\n",
    "    SVM = svm.SVC()\n",
    "    \n",
    "    model = SVM.fit(train_features, labels_train)\n",
    "    \n",
    "    print \"Predicting based on model... \"\n",
    "    result = model.predict(test_features)\n",
    "    \n",
    "    print \"Calculating error...\"\n",
    "    error = get_accuracy(result, labels_test)\n",
    "    \n",
    "    print \"The error of SVM \", error\n",
    "    \n",
    "    print \"Done\"\n",
    "    \n",
    "    finish_time = time.time() - start_time\n",
    "    print \"This took %s seconds\" %(finish_time)\n",
    "    return result, error, finish_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def random_forest_model(train_features, test_features, labels_train, labels_test):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    start_time = time.time()\n",
    "    print \"Training the random forest...\"\n",
    "    forest = RandomForestClassifier(n_estimators = 100, random_state = 23) \n",
    "\n",
    "    # Fit the forest to the training set, using the bag of words as \n",
    "    # features and the sentiment labels as the response variable\n",
    "    #\n",
    "    # This may take a few minutes to run\n",
    "    forest = forest.fit( train_features, labels_train)\n",
    "    \n",
    "    print \"Predicting based on model...\"\n",
    "    result = forest.predict(test_features)\n",
    "    \n",
    "    print \"Calculating error...\"\n",
    "    error = get_accuracy(result, labels_test)\n",
    "    \n",
    "    print \"The error of random forest with 100 trees is \", error\n",
    "    \n",
    "    print \"Done\"\n",
    "    \n",
    "    finish_time = time.time() - start_time\n",
    "    print \"This took %s seconds\" %(finish_time)\n",
    "    return result, error, finish_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neural_network_model(train_features, test_features, labels_train, labels_test):\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "    start_time = time.time()\n",
    "    print \"Training neural network...\"\n",
    "    clf = MLPClassifier(solver='adam', alpha=1e-5, random_state=1)\n",
    "\n",
    "    NN = clf.fit(train_data_features, labels_train)\n",
    "    \n",
    "    print \"Predicting based on model...\"\n",
    "    result = clf.predict(test_data_features)\n",
    "    \n",
    "    print \"Calculating error...\"\n",
    "    error = get_accuracy(result, labels_test)\n",
    "    \n",
    "    print \"The error of Neural Network with \", error\n",
    "    \n",
    "    print \"Done\"\n",
    "    \n",
    "    finish_time = time.time() - start_time\n",
    "    print \"This took %s seconds\" %(finish_time)\n",
    "    return result, error, finish_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def Gaussian_Naive_Bayes_model(train_features, test_features, labels_train, labels_test):\n",
    "    from sklearn.naive_bayes import GaussianNB\n",
    "    start_time = time.time()\n",
    "    print \"Training Gaussian Naive Bayes model... \"\n",
    "    GNB = GaussianNB()\n",
    "    \n",
    "    model = GNB.fit(train_features, labels_train)\n",
    "    \n",
    "    print \"Predicting based on model... \"\n",
    "    result = model.predict(test_features)\n",
    "    \n",
    "    print \"Calculating error...\"\n",
    "    error = get_accuracy(result, labels_test)\n",
    "    \n",
    "    print \"The error of Gaussian Naive Bayes \", error\n",
    "    \n",
    "    print \"Done\"\n",
    "    \n",
    "    finish_time = time.time() - start_time\n",
    "    print \"This took %s seconds\" %(finish_time)\n",
    "    return result, error, finish_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def KNN_model(train_features, test_features, labels_train, labels_test):\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    start_time = time.time()\n",
    "    print \"Training KNN model... \"\n",
    "    KNN = KNeighborsClassifier(n_neighbors = 5)\n",
    "    \n",
    "    model = KNN.fit(train_features, labels_train)\n",
    "    \n",
    "    print \"Predicting based on model... \"\n",
    "    result = model.predict(test_features)\n",
    "    \n",
    "    print \"Calculating error...\"\n",
    "    error = get_accuracy(result, labels_test)\n",
    "    \n",
    "    print \"The error of KNN \", error\n",
    "    \n",
    "    print \"Done\"\n",
    "    \n",
    "    finish_time = time.time() - start_time\n",
    "    print \"This took %s seconds\" %(finish_time)\n",
    "    return result, error, finish_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bag_of_words_df = open_bow_df(\"./Results/Bag_of_Words_df.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "col_names = [\"Calssification Model\", \"Feature Count\", \"Error\", \"Time\"]\n",
    "model_df = pd.DataFrame(columns = col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the training set article sentences...\n",
      "\n",
      "Creating the bag of words...\n",
      "\n",
      "Cleaning and parsing the test set movie reviews...\n",
      "\n",
      "Done! Produced train, test split with  1000  features\n",
      "Training the random forest...\n",
      "Predicting based on model...\n",
      "Calculating error...\n",
      "The error of random forest with 100 trees is  0.162581445858\n",
      "Done\n",
      "This took 36.5700960159 seconds\n",
      "Training neural network...\n",
      "Predicting based on model...\n",
      "Calculating error...\n",
      "The error of Neural Network with  0.177060709484\n",
      "Done\n",
      "This took 27.4707429409 seconds\n",
      "Training Linear Regression model... \n",
      "Predicting based on model... \n",
      "Calculating error...\n",
      "The error of linear regression (normalized)  1.0\n",
      "Done\n",
      "This took 3.02640604973 seconds\n",
      "Training Logistic Regression model... \n",
      "Predicting based on model... \n",
      "Calculating error...\n",
      "The error of logistic regression  0.189368083566\n",
      "Done\n",
      "This took 3.09586000443 seconds\n",
      "Training Support Vector Machines model... \n",
      "Predicting based on model... \n",
      "Calculating error...\n",
      "The error of SVM  0.199917261351\n",
      "Done\n",
      "This took 370.651525021 seconds\n",
      "Training Gaussian Naive Bayes model... \n",
      "Predicting based on model... \n",
      "Calculating error...\n",
      "The error of Gaussian Naive Bayes  0.72644534078\n",
      "Done\n",
      "This took 0.587270975113 seconds\n",
      "Training KNN model... \n",
      "Predicting based on model... \n",
      "Calculating error...\n",
      "The error of KNN  0.195676905575\n",
      "Done\n",
      "This took 293.572463036 seconds\n"
     ]
    }
   ],
   "source": [
    "train_data_features, test_data_features, labels_train, labels_test = bag_of_words_and_prediction(bag_of_words_df, 1000)\n",
    "_, ran_for_error_1000, ran_for_time_1000 = random_forest_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, NN_error_1000, NN_time_1000 = neural_network_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, linear_error_1000, linear_time_1000 = linear_reg_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, logistic_error_1000, logistic_time_1000 = logistic_reg_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, SVM_error_1000, SVM_time_1000 = SVM_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, GNB_error_1000, GNB_time_1000 = Gaussian_Naive_Bayes_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, KNN_error_1000, KNN_time_1000 = KNN_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "model_df.loc[0] = [\"Random Forest (100 trees, random state = 23)\", 1000, ran_for_error_1000, ran_for_time_1000]\n",
    "model_df.loc[1] = [\"Neural Network\", 1000, NN_error_1000, NN_time_1000]\n",
    "model_df.loc[2] = [\"Linear Regression\", 1000, linear_error_1000, linear_time_1000]\n",
    "model_df.loc[3] = [\"Logistic Regression\", 1000, logistic_error_1000, logistic_time_1000]\n",
    "model_df.loc[4] = [\"Support Vector Machines\", 1000, SVM_error_1000, SVM_time_1000]\n",
    "model_df.loc[5] = [\"Gaussian Naive Bayes\", 1000, GNB_error_1000, GNB_time_1000]\n",
    "model_df.loc[6] = [\"K Nearest Neighbor (5)\", 1000, KNN_error_1000, KNN_time_1000]\n",
    "model_df.to_csv(\"Model_df.tsv\", sep = '\\t', index = False)\n",
    "del train_data_features, test_data_features, labels_train, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the training set article sentences...\n",
      "\n",
      "Creating the bag of words...\n",
      "\n",
      "Cleaning and parsing the test set movie reviews...\n",
      "\n",
      "Done! Produced train, test split with  2000  features\n",
      "Training the random forest...\n",
      "Predicting based on model...\n",
      "Calculating error...\n",
      "The error of random forest with 100 trees is  0.163615678974\n",
      "Done\n",
      "This took 71.2901079655 seconds\n",
      "Training neural network...\n",
      "Predicting based on model...\n",
      "Calculating error...\n",
      "The error of Neural Network with  0.182231875065\n",
      "Done\n",
      "This took 98.7518360615 seconds\n",
      "Training Linear Regression model... \n",
      "Predicting based on model... \n",
      "Calculating error...\n",
      "The error of linear regression (normalized)  1.0\n",
      "Done\n",
      "This took 13.6381788254 seconds\n",
      "Training Logistic Regression model... \n",
      "Predicting based on model... \n",
      "Calculating error...\n",
      "The error of logistic regression  0.186472230841\n",
      "Done\n",
      "This took 1.86303782463 seconds\n",
      "Training Support Vector Machines model... \n",
      "Predicting based on model... \n",
      "Calculating error...\n",
      "The error of SVM  0.20053780122\n",
      "Done\n",
      "This took 688.541300058 seconds\n",
      "Training Gaussian Naive Bayes model... \n",
      "Predicting based on model... \n",
      "Calculating error...\n",
      "The error of Gaussian Naive Bayes  0.677319267763\n",
      "Done\n",
      "This took 1.11774396896 seconds\n",
      "Training KNN model... \n",
      "Predicting based on model... \n",
      "Calculating error...\n",
      "The error of KNN  0.195780328886\n",
      "Done\n",
      "This took 571.975269794 seconds\n"
     ]
    }
   ],
   "source": [
    "train_data_features, test_data_features, labels_train, labels_test = bag_of_words_and_prediction(bag_of_words_df, 2000)\n",
    "_, ran_for_error_2000, ran_for_time_2000 = random_forest_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, NN_error_2000, NN_time_2000 = neural_network_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, linear_error_2000, linear_time_2000 = linear_reg_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, logistic_error_2000, logistic_time_2000 = logistic_reg_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, SVM_error_2000, SVM_time_2000 = SVM_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, GNB_error_2000, GNB_time_2000 = Gaussian_Naive_Bayes_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, KNN_error_2000, KNN_time_2000 = KNN_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "model_df.loc[7] = [\"Random Forest (100 trees, random state = 23)\", 2000, ran_for_error_2000, ran_for_time_2000]\n",
    "model_df.loc[8] = [\"Neural Network\", 2000, NN_error_2000, NN_time_2000]\n",
    "model_df.loc[9] = [\"Linear Regression\", 2000, linear_error_2000, linear_time_2000]\n",
    "model_df.loc[10] = [\"Logistic Regression\", 2000, logistic_error_2000, logistic_time_2000]\n",
    "model_df.loc[11] = [\"Support Vector Machines\", 2000, SVM_error_2000, SVM_time_2000]\n",
    "model_df.loc[12] = [\"Gaussian Naive Bayes\", 2000, GNB_error_2000, GNB_time_2000]\n",
    "model_df.loc[13] = [\"K Nearest Neighbor (5)\", 2000, KNN_error_2000, KNN_time_2000]\n",
    "model_df.to_csv(\"Model_df.tsv\", sep = '\\t', index = False)\n",
    "del train_data_features, test_data_features, labels_train, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the training set article sentences...\n",
      "\n",
      "Creating the bag of words...\n",
      "\n",
      "Cleaning and parsing the test set movie reviews...\n",
      "\n",
      "Done! Produced train, test split with  3000  features\n",
      "Training the random forest...\n",
      "Predicting based on model...\n",
      "Calculating error...\n",
      "The error of random forest with 100 trees is  0.160099286379\n",
      "Done\n",
      "This took 99.9864411354 seconds\n",
      "Training neural network...\n",
      "Predicting based on model...\n",
      "Calculating error...\n",
      "The error of Neural Network with  0.179336022339\n",
      "Done\n",
      "This took 116.081527948 seconds\n",
      "Training Linear Regression model... \n",
      "Predicting based on model... \n",
      "Calculating error...\n",
      "The error of linear regression (normalized)  1.0\n",
      "Done\n",
      "This took 31.860863924 seconds\n",
      "Training Logistic Regression model... \n",
      "Predicting based on model... \n",
      "Calculating error...\n",
      "The error of logistic regression  0.187196194022\n",
      "Done\n",
      "This took 2.18341302872 seconds\n",
      "Training Support Vector Machines model... \n",
      "Predicting based on model... \n",
      "Calculating error...\n",
      "The error of SVM  0.201365187713\n",
      "Done\n",
      "This took 1058.953444 seconds\n",
      "Training Gaussian Naive Bayes model... \n",
      "Predicting based on model... \n",
      "Calculating error...\n",
      "The error of Gaussian Naive Bayes  0.649705243562\n",
      "Done\n",
      "This took 1.62899899483 seconds\n",
      "Training KNN model... \n",
      "Predicting based on model... \n",
      "Calculating error...\n",
      "The error of KNN  0.206432929982\n",
      "Done\n",
      "This took 846.931102991 seconds\n"
     ]
    }
   ],
   "source": [
    "train_data_features, test_data_features, labels_train, labels_test = bag_of_words_and_prediction(bag_of_words_df, 3000)\n",
    "_, ran_for_error_3000, ran_for_time_3000 = random_forest_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, NN_error_3000, NN_time_3000 = neural_network_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, linear_error_3000, linear_time_3000 = linear_reg_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, logistic_error_3000, logistic_time_3000 = logistic_reg_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, SVM_error_3000, SVM_time_3000 = SVM_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, GNB_error_3000, GNB_time_3000 = Gaussian_Naive_Bayes_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, KNN_error_3000, KNN_time_3000 = KNN_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "model_df.loc[14] = [\"Random Forest (100 trees, random state = 23)\", 3000, ran_for_error_3000, ran_for_time_3000]\n",
    "model_df.loc[15] = [\"Neural Network\", 3000, NN_error_3000, NN_time_3000]\n",
    "model_df.loc[16] = [\"Linear Regression\", 3000, linear_error_3000, linear_time_3000]\n",
    "model_df.loc[17] = [\"Logistic Regression\", 3000, logistic_error_3000, logistic_time_3000]\n",
    "model_df.loc[18] = [\"Support Vector Machines\", 3000, SVM_error_3000, SVM_time_3000]\n",
    "model_df.loc[19] = [\"Gaussian Naive Bayes\", 3000, GNB_error_3000, GNB_time_3000]\n",
    "model_df.loc[20] = [\"K Nearest Neighbor (5)\", 3000, KNN_error_3000, KNN_time_3000]\n",
    "model_df.to_csv(\"Model_df.tsv\", sep = '\\t', index = False)\n",
    "del train_data_features, test_data_features, labels_train, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the training set article sentences...\n",
      "\n",
      "Creating the bag of words...\n",
      "\n",
      "Cleaning and parsing the test set movie reviews...\n",
      "\n",
      "Done! Produced train, test split with  4000  features\n",
      "Training the random forest...\n",
      "Predicting based on model...\n",
      "Calculating error...\n",
      "The error of random forest with 100 trees is  0.161236942807\n",
      "Done\n",
      "This took 135.078104019 seconds\n",
      "Training neural network...\n",
      "Predicting based on model...\n",
      "Calculating error...\n",
      "The error of Neural Network with  0.183679801427\n",
      "Done\n",
      "This took 151.013469934 seconds\n",
      "Training Linear Regression model... \n",
      "Predicting based on model... \n",
      "Calculating error...\n",
      "The error of linear regression (normalized)  1.0\n",
      "Done\n",
      "This took 73.6077618599 seconds\n",
      "Training Logistic Regression model... \n",
      "Predicting based on model... \n",
      "Calculating error...\n",
      "The error of logistic regression  0.185437997725\n",
      "Done\n",
      "This took 2.41880202293 seconds\n",
      "Training Support Vector Machines model... \n",
      "Predicting based on model... \n",
      "Calculating error...\n",
      "The error of SVM  0.202813114076\n",
      "Done\n",
      "This took 1360.37591505 seconds\n",
      "Training Gaussian Naive Bayes model... \n",
      "Predicting based on model... \n",
      "Calculating error...\n",
      "The error of Gaussian Naive Bayes  0.628813734616\n",
      "Done\n",
      "This took 2.34500098228 seconds\n",
      "Training KNN model... \n",
      "Predicting based on model... \n",
      "Calculating error...\n",
      "The error of KNN  0.192987899473\n",
      "Done\n",
      "This took 1186.99991488 seconds\n"
     ]
    }
   ],
   "source": [
    "train_data_features, test_data_features, labels_train, labels_test = bag_of_words_and_prediction(bag_of_words_df, 4000)\n",
    "_, ran_for_error_4000, ran_for_time_4000 = random_forest_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, NN_error_4000, NN_time_4000 = neural_network_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, linear_error_4000, linear_time_4000 = linear_reg_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, logistic_error_4000, logistic_time_4000 = logistic_reg_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, SVM_error_4000, SVM_time_4000 = SVM_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, GNB_error_4000, GNB_time_4000 = Gaussian_Naive_Bayes_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, KNN_error_4000, KNN_time_4000 = KNN_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "model_df.loc[21] = [\"Random Forest (100 trees, random state = 23)\", 4000, ran_for_error_4000, ran_for_time_4000]\n",
    "model_df.loc[22] = [\"Neural Network\", 4000, NN_error_4000, NN_time_4000]\n",
    "model_df.loc[23] = [\"Linear Regression\", 4000, linear_error_4000, linear_time_4000]\n",
    "model_df.loc[24] = [\"Logistic Regression\", 4000, logistic_error_4000, logistic_time_4000]\n",
    "model_df.loc[25] = [\"Support Vector Machines\", 4000, SVM_error_4000, SVM_time_4000]\n",
    "model_df.loc[26] = [\"Gaussian Naive Bayes\", 4000, GNB_error_4000, GNB_time_4000]\n",
    "model_df.loc[27] = [\"K Nearest Neighbor (5)\", 4000, KNN_error_4000, KNN_time_4000]\n",
    "model_df.to_csv(\"Model_df.tsv\", sep = '\\t', index = False)\n",
    "del train_data_features, test_data_features, labels_train, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the training set article sentences...\n",
      "\n",
      "Creating the bag of words...\n",
      "\n",
      "Cleaning and parsing the test set movie reviews...\n",
      "\n",
      "Done! Produced train, test split with  5000  features\n",
      "Training the random forest...\n",
      "Predicting based on model...\n",
      "Calculating error...\n",
      "The error of random forest with 100 trees is  0.15823766677\n",
      "Done\n",
      "This took 175.911018848 seconds\n",
      "Training neural network...\n",
      "Predicting based on model...\n",
      "Calculating error...\n",
      "The error of Neural Network with  0.185334574413\n",
      "Done\n",
      "This took 183.063563108 seconds\n",
      "Training Linear Regression model... \n",
      "Predicting based on model... \n",
      "Calculating error...\n",
      "The error of linear regression (normalized)  1.0\n",
      "Done\n",
      "This took 120.363672972 seconds\n",
      "Training Logistic Regression model... \n",
      "Predicting based on model... \n",
      "Calculating error...\n",
      "The error of logistic regression  0.180473678767\n",
      "Done\n",
      "This took 2.56825780869 seconds\n",
      "Training Support Vector Machines model... \n",
      "Predicting based on model... \n",
      "Calculating error...\n",
      "The error of SVM  0.203123384011\n",
      "Done\n",
      "This took 1664.78698611 seconds\n",
      "Training Gaussian Naive Bayes model... \n",
      "Predicting based on model... \n",
      "Calculating error...\n",
      "The error of Gaussian Naive Bayes  0.618471403454\n",
      "Done\n",
      "This took 2.9519097805 seconds\n",
      "Training KNN model... \n",
      "Predicting based on model... \n",
      "Calculating error...\n",
      "The error of KNN  0.19091943324\n",
      "Done\n",
      "This took 1482.63720608 seconds\n"
     ]
    }
   ],
   "source": [
    "train_data_features, test_data_features, labels_train, labels_test = bag_of_words_and_prediction(bag_of_words_df, 5000)\n",
    "_, ran_for_error_5000, ran_for_time_5000 = random_forest_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, NN_error_5000, NN_time_5000 = neural_network_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, linear_error_5000, linear_time_5000 = linear_reg_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, logistic_error_5000, logistic_time_5000 = logistic_reg_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, SVM_error_5000, SVM_time_5000 = SVM_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, GNB_error_5000, GNB_time_5000 = Gaussian_Naive_Bayes_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, KNN_error_5000, KNN_time_5000 = KNN_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "model_df.loc[28] = [\"Random Forest (100 trees, random state = 23)\", 5000, ran_for_error_5000, ran_for_time_5000]\n",
    "model_df.loc[29] = [\"Neural Network\", 5000, NN_error_5000, NN_time_5000]\n",
    "model_df.loc[30] = [\"Linear Regression\", 5000, linear_error_5000, linear_time_5000]\n",
    "model_df.loc[31] = [\"Logistic Regression\", 5000, logistic_error_5000, logistic_time_5000]\n",
    "model_df.loc[32] = [\"Support Vector Machines\", 5000, SVM_error_5000, SVM_time_5000]\n",
    "model_df.loc[33] = [\"Gaussian Naive Bayes\", 5000, GNB_error_5000, GNB_time_5000]\n",
    "model_df.loc[34] = [\"K Nearest Neighbor (5)\", 5000, KNN_error_5000, KNN_time_5000]\n",
    "model_df.to_csv(\"Model_df.tsv\", sep = '\\t', index = False)\n",
    "del train_data_features, test_data_features, labels_train, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the training set article sentences...\n",
      "\n",
      "Creating the bag of words...\n",
      "\n",
      "Cleaning and parsing the test set movie reviews...\n",
      "\n",
      "Done! Produced train, test split with  6000  features\n",
      "Training the random forest...\n",
      "Predicting based on model...\n",
      "Calculating error...\n",
      "The error of random forest with 100 trees is  0.161754059365\n",
      "Done\n",
      "This took 240.822900057 seconds\n",
      "Training neural network...\n",
      "Predicting based on model...\n",
      "Calculating error...\n",
      "The error of Neural Network with  0.177888095977\n",
      "Done\n",
      "This took 339.812659979 seconds\n",
      "Training Linear Regression model... \n",
      "Predicting based on model... \n",
      "Calculating error...\n",
      "The error of linear regression (normalized)  1.0\n",
      "Done\n",
      "This took 265.331923962 seconds\n",
      "Training Logistic Regression model... \n",
      "Predicting based on model... \n",
      "Calculating error...\n",
      "The error of logistic regression  0.180473678767\n",
      "Done\n",
      "This took 3.36719989777 seconds\n",
      "Training Support Vector Machines model... \n",
      "Predicting based on model... \n",
      "Calculating error...\n",
      "The error of SVM  0.204054193815\n",
      "Done\n",
      "This took 2093.50505805 seconds\n",
      "Training Gaussian Naive Bayes model... \n",
      "Predicting based on model... \n",
      "Calculating error...\n",
      "The error of Gaussian Naive Bayes  0.608439342228\n",
      "Done\n",
      "This took 3.82573390007 seconds\n",
      "Training KNN model... \n",
      "Predicting based on model... \n",
      "Calculating error...\n",
      "The error of KNN  0.191746819733\n",
      "Done\n",
      "This took 1724.617558 seconds\n"
     ]
    }
   ],
   "source": [
    "train_data_features, test_data_features, labels_train, labels_test = bag_of_words_and_prediction(bag_of_words_df, 6000)\n",
    "_, ran_for_error_6000, ran_for_time_6000 = random_forest_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, NN_error_6000, NN_time_6000 = neural_network_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, linear_error_6000, linear_time_6000 = linear_reg_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, logistic_error_6000, logistic_time_6000 = logistic_reg_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, SVM_error_6000, SVM_time_6000 = SVM_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, GNB_error_6000, GNB_time_6000 = Gaussian_Naive_Bayes_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, KNN_error_6000, KNN_time_6000 = KNN_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "model_df.loc[35] = [\"Random Forest (100 trees, random state = 23)\", 6000, ran_for_error_6000, ran_for_time_6000]\n",
    "model_df.loc[36] = [\"Neural Network\", 6000, NN_error_6000, NN_time_4000]\n",
    "model_df.loc[37] = [\"Linear Regression\", 6000, linear_error_6000, linear_time_6000]\n",
    "model_df.loc[38] = [\"Logistic Regression\", 6000, logistic_error_6000, logistic_time_6000]\n",
    "model_df.loc[39] = [\"Support Vector Machines\", 6000, SVM_error_6000, SVM_time_6000]\n",
    "model_df.loc[40] = [\"Gaussian Naive Bayes\", 6000, GNB_error_6000, GNB_time_6000]\n",
    "model_df.loc[41] = [\"K Nearest Neighbor (5)\", 6000, KNN_error_6000, KNN_time_6000]\n",
    "model_df.to_csv(\"Model_df.tsv\", sep = '\\t', index = False)\n",
    "del train_data_features, test_data_features, labels_train, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the training set article sentences...\n",
      "\n",
      "Creating the bag of words...\n",
      "\n",
      "Cleaning and parsing the test set movie reviews...\n",
      "\n",
      "Done! Produced train, test split with  7000  features\n",
      "Training the random forest...\n",
      "Predicting based on model...\n",
      "Calculating error...\n",
      "The error of random forest with 100 trees is  0.159995863068\n",
      "Done\n",
      "This took 267.895978928 seconds\n",
      "Training neural network...\n",
      "Predicting based on model...\n",
      "Calculating error...\n",
      "The error of Neural Network with  0.180059985521\n",
      "Done\n",
      "This took 408.439840078 seconds\n",
      "Training Linear Regression model... \n",
      "Predicting based on model... \n",
      "Calculating error...\n",
      "The error of linear regression (normalized)  1.0\n",
      "Done\n",
      "This took 512.624369144 seconds\n",
      "Training Logistic Regression model... \n",
      "Predicting based on model... \n",
      "Calculating error...\n",
      "The error of logistic regression  0.180783948702\n",
      "Done\n",
      "This took 4.40998387337 seconds\n",
      "Training Support Vector Machines model... \n",
      "Predicting based on model... \n",
      "Calculating error...\n",
      "The error of SVM  0.204261040439\n",
      "Done\n",
      "This took 2373.17417789 seconds\n",
      "Training Gaussian Naive Bayes model... \n",
      "Predicting based on model... \n",
      "Calculating error...\n",
      "The error of Gaussian Naive Bayes  0.597890164443\n",
      "Done\n",
      "This took 5.03756999969 seconds\n",
      "Training KNN model... \n",
      "Predicting based on model... \n",
      "Calculating error...\n",
      "The error of KNN  0.192884476161\n",
      "Done\n",
      "This took 3535.605829 seconds\n"
     ]
    }
   ],
   "source": [
    "train_data_features, test_data_features, labels_train, labels_test = bag_of_words_and_prediction(bag_of_words_df, 7000)\n",
    "_, ran_for_error_7000, ran_for_time_7000 = random_forest_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, NN_error_7000, NN_time_7000 = neural_network_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, linear_error_7000, linear_time_7000 = linear_reg_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, logistic_error_7000, logistic_time_7000 = logistic_reg_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, SVM_error_7000, SVM_time_7000 = SVM_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, GNB_error_7000, GNB_time_7000 = Gaussian_Naive_Bayes_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, KNN_error_7000, KNN_time_7000 = KNN_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "model_df.loc[42] = [\"Random Forest (100 trees, random state = 23)\", 7000, ran_for_error_7000, ran_for_time_7000]\n",
    "model_df.loc[43] = [\"Neural Network\", 7000, NN_error_7000, NN_time_7000]\n",
    "model_df.loc[44] = [\"Linear Regression\", 7000, linear_error_7000, linear_time_7000]\n",
    "model_df.loc[45] = [\"Logistic Regression\", 7000, logistic_error_7000, logistic_time_7000]\n",
    "model_df.loc[46] = [\"Support Vector Machines\", 7000, SVM_error_7000, SVM_time_7000]\n",
    "model_df.loc[47] = [\"Gaussian Naive Bayes\", 7000, GNB_error_7000, GNB_time_7000]\n",
    "model_df.loc[48] = [\"K Nearest Neighbor (5)\", 7000, KNN_error_7000, KNN_time_7000]\n",
    "model_df.to_csv(\"Model_df.tsv\", sep = '\\t', index = False)\n",
    "del train_data_features, test_data_features, labels_train, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaning and parsing the training set article sentences...\n",
      "\n",
      "Creating the bag of words...\n",
      "\n",
      "Cleaning and parsing the test set movie reviews...\n",
      "\n",
      "Done! Produced train, test split with  8000  features\n",
      "Training the random forest...\n"
     ]
    }
   ],
   "source": [
    "train_data_features, test_data_features, labels_train, labels_test = bag_of_words_and_prediction(bag_of_words_df, 8000)\n",
    "_, ran_for_error_8000, ran_for_time_8000 = random_forest_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, NN_error_8000, NN_time_8000 = neural_network_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, linear_error_8000, linear_time_8000 = linear_reg_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, logistic_error_8000, logistic_time_8000 = logistic_reg_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, SVM_error_8000, SVM_time_8000 = SVM_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, GNB_error_8000, GNB_time_8000 = Gaussian_Naive_Bayes_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, KNN_error_8000, KNN_time_8000 = KNN_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "model_df.loc[49] = [\"Random Forest (100 trees, random state = 23)\", 8000, ran_for_error_8000, ran_for_time_8000]\n",
    "model_df.loc[50] = [\"Neural Network\", 8000, NN_error_8000, NN_time_8000]\n",
    "model_df.loc[51] = [\"Linear Regression\", 8000, linear_error_8000, linear_time_8000]\n",
    "model_df.loc[52] = [\"Logistic Regression\", 8000, logistic_error_8000, logistic_time_8000]\n",
    "model_df.loc[53] = [\"Support Vector Machines\", 8000, SVM_error_8000, SVM_time_8000]\n",
    "model_df.loc[54] = [\"Gaussian Naive Bayes\", 8000, GNB_error_8000, GNB_time_8000]\n",
    "model_df.loc[55] = [\"K Nearest Neighbor (5)\", 8000, KNN_error_8000, KNN_time_8000]\n",
    "model_df.to_csv(\"Model_df.tsv\", sep = '\\t', index = False)\n",
    "del train_data_features, test_data_features, labels_train, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_features, test_data_features, labels_train, labels_test = bag_of_words_and_prediction(bag_of_words_df, 9000)\n",
    "_, ran_for_error_9000, ran_for_time_9000 = random_forest_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, NN_error_9000, NN_time_9000 = neural_network_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, linear_error_9000, linear_time_9000 = linear_reg_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, logistic_error_9000, logistic_time_9000 = logistic_reg_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, SVM_error_9000, SVM_time_9000 = SVM_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, GNB_error_9000, GNB_time_9000 = Gaussian_Naive_Bayes_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, KNN_error_9000, KNN_time_9000 = KNN_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "model_df.loc[56] = [\"Random Forest (100 trees, random state = 23)\", 9000, ran_for_error_9000, ran_for_time_9000]\n",
    "model_df.loc[57] = [\"Neural Network\", 9000, NN_error_9000, NN_time_9000]\n",
    "model_df.loc[58] = [\"Linear Regression\", 9000, linear_error_9000, linear_time_9000]\n",
    "model_df.loc[59] = [\"Logistic Regression\", 9000, logistic_error_9000, logistic_time_9000]\n",
    "model_df.loc[60] = [\"Support Vector Machines\", 9000, SVM_error_9000, SVM_time_9000]\n",
    "model_df.loc[61] = [\"Gaussian Naive Bayes\", 9000, GNB_error_9000, GNB_time_9000]\n",
    "model_df.loc[62] = [\"K Nearest Neighbor (5)\", 9000, KNN_error_9000, KNN_time_9000]\n",
    "model_df.to_csv(\"Model_df.tsv\", sep = '\\t', index = False)\n",
    "del train_data_features, test_data_features, labels_train, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_features, test_data_features, labels_train, labels_test = bag_of_words_and_prediction(bag_of_words_df, 10000)\n",
    "_, ran_for_error_10000, ran_for_time_10000 = random_forest_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, NN_error_10000, NN_time_10000 = neural_network_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, linear_error_10000, linear_time_10000 = linear_reg_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, logistic_error_10000, logistic_time_10000 = logistic_reg_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, SVM_error_10000, SVM_time_10000 = SVM_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, GNB_error_10000, GNB_time_10000 = Gaussian_Naive_Bayes_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "_, KNN_error_10000, KNN_time_10000 = KNN_model(train_data_features, test_data_features, labels_train, labels_test)\n",
    "model_df.loc[63] = [\"Random Forest (100 trees, random state = 23)\", 10000, ran_for_error_10000, ran_for_time_10000]\n",
    "model_df.loc[64] = [\"Neural Network\", 10000, NN_error_10000, NN_time_10000]\n",
    "model_df.loc[65] = [\"Linear Regression\", 10000, linear_error_10000, linear_time_10000]\n",
    "model_df.loc[66] = [\"Logistic Regression\", 10000, logistic_error_10000, logistic_time_10000]\n",
    "model_df.loc[67] = [\"Support Vector Machines\", 10000, SVM_error_10000, SVM_time_10000]\n",
    "model_df.loc[68] = [\"Gaussian Naive Bayes\", 10000, GNB_error_10000, GNB_time_10000]\n",
    "model_df.loc[69] = [\"K Nearest Neighbor (5)\", 10000, KNN_error_10000, KNN_time_10000]\n",
    "model_df.to_csv(\"Model_df.tsv\", sep = '\\t', index = False)\n",
    "del train_data_features, test_data_features, labels_train, labels_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print \"Done!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
